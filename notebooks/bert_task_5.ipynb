{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install shap lime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUW9TMgBylim",
        "outputId": "411276b3-4256-4dcf-a231-8b7b4ec692d1"
      },
      "id": "VUW9TMgBylim",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=5428a238faa88108d4ddbb6877b956be4cc7e75d4fb1346d4391f6939379d113\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from transformers import pipeline\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "2XSI3w1YynsB"
      },
      "id": "2XSI3w1YynsB",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "model_dir = \"/content/xlmr-ner-amharic\"\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n"
      ],
      "metadata": {
        "id": "7Nxmp1p4yqKF"
      },
      "id": "7Nxmp1p4yqKF",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TokenClassificationPipeline\n",
        "\n",
        "ner_pipe = TokenClassificationPipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    aggregation_strategy=\"simple\",  # group subwords\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRiKpor7ytzG",
        "outputId": "b22c9c18-5d29-4126-bd6a-060418aee262"
      },
      "id": "ZRiKpor7ytzG",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"·ã®·àÄ·åà·à´·âΩ·äï ·àù·à≠·âµ üá™üáπ 2600 ·â•·à≠ ·â•·âª 0911871330 ·â¶·àå ·àò·ã∞·àê·äï·ã´·àà·àù ·ä¶·àÆ·àö·ã´ ·àÖ·äï·çÉ 1·äõ ·çé·âÖ 104 ·âÅ·å•·à≠ ·ä©·à© ·å´·àõ ·ã®·â¥·àå·åç·à´·àù ·ä†·â£·àç ·ã≠·àÅ·äë T.me/kuruwear\",\n",
        "    \"Shewa Brand,@Shewabrand,1269 under armour CHARGED IMPULSE size 40--45 MADE IN VIETNAM SHEWA BRAND ·ä†·ãµ·à´·àª ·ãµ·à¨·ã≥·ãã  ·ä†·à∏·ãã ·àö·äì 1 ·çé·âÖ ·ä•·äï·åà·äõ·àà·äï ·àµ·àç·ä≠ 0987336458 ·ã®·â§·âµ ·âÅ·å•·à≠ 109 ·ä•·äì 110\",\n",
        "    \"Made In VIETNAM Size #40 #41 #42 #43  Price: 5200 Br INBOX : @Maraki2211  ·àµ·àç·ä≠¬†: +251 913321831  ·ä†·ãµ·à´·àª - ·ä†·ã≤·àµ ·ä†·â†·â£, ·àú·ä≠·à≤·äÆ·ç° ·ä® ·ä¨·ä¨·à≠ ·àÖ·äï·åª 50·àú ·ãà·à®·ãµ ·â•·àé ·ä†·ã≠·àò·äï ·àÖ·äï·çÉ¬† ·åç·à´·ãç·äï·ãµ ·çç·àé·à≠ ·àã·ã≠·ç° ·ã®·à±·âÖ ·âÅ.012 Maraki Brand‚Ñ¢ ‚îÉ·àõ·à´·ä™ ·â•·à´·äï·ãµ\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "L6qiR2vxy9hA"
      },
      "id": "L6qiR2vxy9hA",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "# Update this path if your model is saved elsewhere\n",
        "model_path = \"/content/bert-base-amharic\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "id2label = model.config.id2label\n"
      ],
      "metadata": {
        "id": "gTMACmyH7cbn"
      },
      "id": "gTMACmyH7cbn",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tokens(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, is_split_into_words=False)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs).logits\n",
        "\n",
        "    predictions = torch.argmax(outputs, dim=2)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    predicted_labels = [id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "    return list(zip(tokens, predicted_labels))\n"
      ],
      "metadata": {
        "id": "FgKMkdTn7fU1"
      },
      "id": "FgKMkdTn7fU1",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "\"·ã®·àÄ·åà·à´·âΩ·äï ·àù·à≠·âµ üá™üáπ 2600 ·â•·à≠ ·â•·âª 0911871330 ·â¶·àå ·àò·ã∞·àê·äï·ã´·àà·àù ·ä¶·àÆ·àö·ã´ ·àÖ·äï·çÉ 1·äõ ·çé·âÖ 104 ·âÅ·å•·à≠ ·ä©·à© ·å´·àõ ·ã®·â¥·àå·åç·à´·àù ·ä†·â£·àç ·ã≠·àÅ·äë T.me/kuruwear\",\n",
        "    \"Shewa Brand,@Shewabrand,1269 under armour CHARGED IMPULSE size 40--45 MADE IN VIETNAM SHEWA BRAND ·ä†·ãµ·à´·àª ·ãµ·à¨·ã≥·ãã  ·ä†·à∏·ãã ·àö·äì 1 ·çé·âÖ ·ä•·äï·åà·äõ·àà·äï ·àµ·àç·ä≠ 0987336458 ·ã®·â§·âµ ·âÅ·å•·à≠ 109 ·ä•·äì 110\",\n",
        "    \"Made In VIETNAM Size #40 #41 #42 #43  Price: 5200 Br INBOX : @Maraki2211  ·àµ·àç·ä≠¬†: +251 913321831  ·ä†·ãµ·à´·àª - ·ä†·ã≤·àµ ·ä†·â†·â£, ·àú·ä≠·à≤·äÆ·ç° ·ä® ·ä¨·ä¨·à≠ ·àÖ·äï·åª 50·àú ·ãà·à®·ãµ ·â•·àé ·ä†·ã≠·àò·äï ·àÖ·äï·çÉ¬† ·åç·à´·ãç·äï·ãµ ·çç·àé·à≠ ·àã·ã≠·ç° ·ã®·à±·âÖ ·âÅ.012 Maraki Brand‚Ñ¢ ‚îÉ·àõ·à´·ä™ ·â•·à´·äï·ãµ\",\n",
        "]\n",
        "\n",
        "for sent in test_sentences:\n",
        "    print(f\"\\nüìå Sentence: {sent}\")\n",
        "    for token, label in predict_tokens(sent):\n",
        "        print(f\"{token:15} {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3lOfsiI7rz3",
        "outputId": "a3ab5247-f1ad-48e9-f367-00b67a9e0fab"
      },
      "id": "p3lOfsiI7rz3",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå Sentence: ·ã®·àÄ·åà·à´·âΩ·äï ·àù·à≠·âµ üá™üáπ 2600 ·â•·à≠ ·â•·âª 0911871330 ·â¶·àå ·àò·ã∞·àê·äï·ã´·àà·àù ·ä¶·àÆ·àö·ã´ ·àÖ·äï·çÉ 1·äõ ·çé·âÖ 104 ·âÅ·å•·à≠ ·ä©·à© ·å´·àõ ·ã®·â¥·àå·åç·à´·àù ·ä†·â£·àç ·ã≠·àÅ·äë T.me/kuruwear\n",
            "[CLS]           O\n",
            "·ã®·àÄ·åà·à´·âΩ·äï          O\n",
            "·àù·à≠·âµ             O\n",
            "üá™üáπ              O\n",
            "260             O\n",
            "##0             O\n",
            "·â•·à≠              O\n",
            "·â•·âª              O\n",
            "09              O\n",
            "##11            O\n",
            "##871           I-Product\n",
            "##33            O\n",
            "##0             O\n",
            "·â¶·àå              O\n",
            "·àò·ã∞              O\n",
            "##·àê·äï            O\n",
            "##·ã´·àà            O\n",
            "##·àù             O\n",
            "·ä¶·àÆ·àö·ã´            I-LOC\n",
            "·àÖ·äï·çÉ             I-LOC\n",
            "1·äõ              I-LOC\n",
            "·çé·âÖ              I-LOC\n",
            "104             O\n",
            "·âÅ·å•·à≠             O\n",
            "·ä©·à©              I-LOC\n",
            "·å´·àõ              I-LOC\n",
            "·ã®·â¥·àå             O\n",
            "##·åç·à´·àù           I-LOC\n",
            "·ä†·â£·àç             O\n",
            "·ã≠·àÅ·äë             I-LOC\n",
            "T               O\n",
            ".               B-Product\n",
            "me              O\n",
            "/               O\n",
            "k               O\n",
            "##uru           I-Product\n",
            "##we            O\n",
            "##ar            O\n",
            "[SEP]           I-LOC\n",
            "\n",
            "üìå Sentence: Shewa Brand,@Shewabrand,1269 under armour CHARGED IMPULSE size 40--45 MADE IN VIETNAM SHEWA BRAND ·ä†·ãµ·à´·àª ·ãµ·à¨·ã≥·ãã  ·ä†·à∏·ãã ·àö·äì 1 ·çé·âÖ ·ä•·äï·åà·äõ·àà·äï ·àµ·àç·ä≠ 0987336458 ·ã®·â§·âµ ·âÅ·å•·à≠ 109 ·ä•·äì 110\n",
            "[CLS]           O\n",
            "She             O\n",
            "##wa            O\n",
            "Br              O\n",
            "##and           O\n",
            ",               O\n",
            "@               O\n",
            "She             O\n",
            "##wa            O\n",
            "##br            O\n",
            "##and           O\n",
            ",               O\n",
            "126             O\n",
            "##9             O\n",
            "under           O\n",
            "ar              O\n",
            "##mo            O\n",
            "##ur            O\n",
            "CHA             O\n",
            "##R             O\n",
            "##GE            O\n",
            "##D             O\n",
            "IM              O\n",
            "##P             O\n",
            "##UL            O\n",
            "##SE            O\n",
            "s               B-Product\n",
            "##ize           I-LOC\n",
            "40              I-LOC\n",
            "-               I-LOC\n",
            "-               O\n",
            "45              I-LOC\n",
            "MA              O\n",
            "##DE            O\n",
            "IN              O\n",
            "VI              O\n",
            "##ET            O\n",
            "##NA            O\n",
            "##M             O\n",
            "SH              O\n",
            "##EW            O\n",
            "##A             O\n",
            "BR              O\n",
            "##AND           O\n",
            "·ä†·ãµ·à´·àª            I-LOC\n",
            "·ãµ·à¨·ã≥·ãã            I-LOC\n",
            "·ä†·à∏·ãã             I-LOC\n",
            "·àö·äì              I-LOC\n",
            "1               O\n",
            "·çé·âÖ              I-LOC\n",
            "·ä•·äï·åà·äõ·àà·äï          O\n",
            "·àµ·àç·ä≠             O\n",
            "09              O\n",
            "##87            O\n",
            "##33            O\n",
            "##64            O\n",
            "##58            O\n",
            "·ã®·â§·âµ             O\n",
            "·âÅ·å•·à≠             O\n",
            "109             O\n",
            "·ä•·äì              I-LOC\n",
            "110             I-LOC\n",
            "[SEP]           I-LOC\n",
            "\n",
            "üìå Sentence: Made In VIETNAM Size #40 #41 #42 #43  Price: 5200 Br INBOX : @Maraki2211  ·àµ·àç·ä≠¬†: +251 913321831  ·ä†·ãµ·à´·àª - ·ä†·ã≤·àµ ·ä†·â†·â£, ·àú·ä≠·à≤·äÆ·ç° ·ä® ·ä¨·ä¨·à≠ ·àÖ·äï·åª 50·àú ·ãà·à®·ãµ ·â•·àé ·ä†·ã≠·àò·äï ·àÖ·äï·çÉ¬† ·åç·à´·ãç·äï·ãµ ·çç·àé·à≠ ·àã·ã≠·ç° ·ã®·à±·âÖ ·âÅ.012 Maraki Brand‚Ñ¢ ‚îÉ·àõ·à´·ä™ ·â•·à´·äï·ãµ\n",
            "[CLS]           O\n",
            "Made            O\n",
            "In              O\n",
            "VI              O\n",
            "##ET            O\n",
            "##NA            O\n",
            "##M             O\n",
            "Si              O\n",
            "##ze            O\n",
            "#               O\n",
            "40              O\n",
            "#               O\n",
            "41              I-LOC\n",
            "#               O\n",
            "42              O\n",
            "#               O\n",
            "43              O\n",
            "Pri             O\n",
            "##ce            O\n",
            ":               O\n",
            "520             I-LOC\n",
            "##0             O\n",
            "Br              O\n",
            "IN              O\n",
            "##BO            O\n",
            "##X             O\n",
            ":               O\n",
            "@               O\n",
            "Mar             O\n",
            "##ak            O\n",
            "##i             O\n",
            "##221           O\n",
            "##1             O\n",
            "·àµ·àç·ä≠             O\n",
            ":               I-LOC\n",
            "+               I-LOC\n",
            "251             O\n",
            "91              O\n",
            "##33            O\n",
            "##21            O\n",
            "##83            O\n",
            "##1             O\n",
            "·ä†·ãµ·à´·àª            I-LOC\n",
            "-               I-LOC\n",
            "·ä†·ã≤·àµ             B-LOC\n",
            "·ä†·â†·â£             I-LOC\n",
            ",               I-LOC\n",
            "·àú·ä≠·à≤·äÆ            I-LOC\n",
            "·ç°               O\n",
            "·ä®               O\n",
            "·ä¨·ä¨              O\n",
            "##·à≠             O\n",
            "·àÖ·äï·åª             O\n",
            "50              O\n",
            "##·àú             O\n",
            "·ãà·à®·ãµ             O\n",
            "·â•·àé              O\n",
            "·ä†·ã≠·àò             O\n",
            "##·äï             O\n",
            "·àÖ·äï·çÉ             O\n",
            "·åç·à´·ãç·äï·ãµ           O\n",
            "·çç·àé              O\n",
            "##·à≠             O\n",
            "·àã·ã≠              O\n",
            "·ç°               O\n",
            "·ã®·à±·âÖ             O\n",
            "·âÅ               O\n",
            ".               O\n",
            "01              O\n",
            "##2             O\n",
            "Mar             O\n",
            "##ak            O\n",
            "##i             O\n",
            "Br              O\n",
            "##and           O\n",
            "##‚Ñ¢             O\n",
            "[UNK]           O\n",
            "·â•·à´·äï·ãµ            O\n",
            "[SEP]           I-LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "def render_colored_ner(tokens_labels):\n",
        "    html = \"\"\n",
        "    for token, label in tokens_labels:\n",
        "        clean_token = token.replace(\"‚ñÅ\", \"\")  # For RoBERTa subwords\n",
        "        if label == \"O\":\n",
        "            html += f\"{clean_token} \"\n",
        "        else:\n",
        "            color = {\n",
        "                \"B-Product\": \"#FFD700\",   # gold\n",
        "                \"I-Product\": \"#FFE066\",\n",
        "                \"B-PRICE\": \"#00BFFF\",     # deep sky blue\n",
        "                \"I-PRICE\": \"#87CEFA\",\n",
        "                \"B-LOC\": \"#90EE90\",       # light green\n",
        "                \"I-LOC\": \"#B2F2BB\"\n",
        "            }.get(label, \"#DDDDDD\")\n",
        "            html += f\"<span style='background-color:{color}; padding:2px; border-radius:3px'>{clean_token}</span> \"\n",
        "    display(HTML(html))\n",
        "\n",
        "# Try it\n",
        "tokens_labels = predict_tokens(test_sentences[0])\n",
        "render_colored_ner(tokens_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ubej6eLW72TK",
        "outputId": "b2e2b7d0-6cdf-4875-abb9-05717547fa2f"
      },
      "id": "ubej6eLW72TK",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "[CLS] ·ã®·àÄ·åà·à´·âΩ·äï ·àù·à≠·âµ üá™üáπ 260 ##0 ·â•·à≠ ·â•·âª 09 ##11 <span style='background-color:#FFE066; padding:2px; border-radius:3px'>##871</span> ##33 ##0 ·â¶·àå ·àò·ã∞ ##·àê·äï ##·ã´·àà ##·àù <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·ä¶·àÆ·àö·ã´</span> <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·àÖ·äï·çÉ</span> <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>1·äõ</span> <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·çé·âÖ</span> 104 ·âÅ·å•·à≠ <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·ä©·à©</span> <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·å´·àõ</span> ·ã®·â¥·àå <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>##·åç·à´·àù</span> ·ä†·â£·àç <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·ã≠·àÅ·äë</span> T <span style='background-color:#FFD700; padding:2px; border-radius:3px'>.</span> me / k <span style='background-color:#FFE066; padding:2px; border-radius:3px'>##uru</span> ##we ##ar <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>[SEP]</span> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_labels = predict_tokens(test_sentences[0])\n",
        "render_colored_ner(tokens_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "2wOQcwYZ74TC",
        "outputId": "ab40f328-63ff-48b1-d77d-531a23fc6e89"
      },
      "id": "2wOQcwYZ74TC",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "[CLS] ·ã®·àÄ·åà·à´·âΩ·äï ·àù·à≠·âµ üá™üáπ 260 ##0 ·â•·à≠ ·â•·âª 09 ##11 <span style='background-color:#FFE066; padding:2px; border-radius:3px'>##871</span> ##33 ##0 ·â¶·àå ·àò·ã∞ ##·àê·äï ##·ã´·àà ##·àù <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·ä¶·àÆ·àö·ã´</span> <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·àÖ·äï·çÉ</span> <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>1·äõ</span> <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·çé·âÖ</span> 104 ·âÅ·å•·à≠ <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·ä©·à©</span> <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·å´·àõ</span> ·ã®·â¥·àå <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>##·åç·à´·àù</span> ·ä†·â£·àç <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>·ã≠·àÅ·äë</span> T <span style='background-color:#FFD700; padding:2px; border-radius:3px'>.</span> me / k <span style='background-color:#FFE066; padding:2px; border-radius:3px'>##uru</span> ##we ##ar <span style='background-color:#B2F2BB; padding:2px; border-radius:3px'>[SEP]</span> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "742a484b"
      },
      "source": [
        "# Task\n",
        "Explain the error in the provided Python code for using SHAP with a Hugging Face `TokenClassificationPipeline`, fix the error by defining a custom output transformation function to make the pipeline output compatible with SHAP, and then generate and visualize SHAP values using the corrected code."
      ],
      "id": "742a484b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d5de7e4"
      },
      "source": [
        "## Define a custom output transform function\n",
        "\n",
        "### Subtask:\n",
        "Create a Python function that takes the output of the `TokenClassificationPipeline` and restructures it to include 'label' and 'score' keys in a format compatible with SHAP.\n"
      ],
      "id": "9d5de7e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d928e936"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `output_transform` function as described in the instructions to restructure the pipeline output.\n",
        "\n"
      ],
      "id": "d928e936"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a06a9e1"
      },
      "source": [
        "def output_transform(pipeline_output):\n",
        "    \"\"\"\n",
        "    Transforms the output of the TokenClassificationPipeline to be compatible with SHAP.\n",
        "\n",
        "    Args:\n",
        "        pipeline_output: The output from the TokenClassificationPipeline.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries with 'label' and 'score' keys for each entity.\n",
        "    \"\"\"\n",
        "    transformed_output = []\n",
        "    for sentence_output in pipeline_output:\n",
        "        sentence_transformed = []\n",
        "        for entity in sentence_output:\n",
        "            sentence_transformed.append({\n",
        "                'label': entity['entity_group'],\n",
        "                'score': entity['score']\n",
        "            })\n",
        "        transformed_output.append(sentence_transformed)\n",
        "    return transformed_output"
      ],
      "id": "9a06a9e1",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e44db6b4"
      },
      "source": [
        "## Initialize shap explainer with the custom transform\n",
        "\n",
        "### Subtask:\n",
        "Instantiate the `shap.Explainer` and pass the custom `output_transform` function to it.\n"
      ],
      "id": "e44db6b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e113eab3"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize the SHAP Explainer with the NER pipeline and the custom output transform function.\n",
        "\n"
      ],
      "id": "e113eab3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ef11be0"
      },
      "source": [
        "explainer = shap.Explainer(ner_pipe, output_transform=output_transform)"
      ],
      "id": "9ef11be0",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "216b72a1"
      },
      "source": [
        "## Generate shap values\n",
        "\n",
        "### Subtask:\n",
        "Generate SHAP values for the test sentences using the initialized SHAP explainer.\n"
      ],
      "id": "216b72a1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2fce6a6"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate SHAP values for the test sentences using the initialized SHAP explainer.\n",
        "\n"
      ],
      "id": "a2fce6a6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "175cc4a7",
        "outputId": "a6588a3a-d79b-48d1-8142-a46cd8757ec4"
      },
      "source": [
        "shap_values = explainer(test_sentences)"
      ],
      "id": "175cc4a7",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-67-2123370617.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 ):\n\u001b[0;32m--> 144\u001b[0;31m                     return super().__call__(\n\u001b[0m\u001b[1;32m    145\u001b[0m                         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                         \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    171\u001b[0m     ):\n\u001b[1;32m    172\u001b[0m         \u001b[0;34m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             ]  # the zero index param tells the masked model what the baseline is\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mf11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mm00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mjoined_masked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_masked_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0m_assert_output_input_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/models/_transformers_pipeline.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, strings)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 output[i, self.label2id[obj[\"label\"]]] = (\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale_to_logits\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 )\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d999323"
      },
      "source": [
        "## Generate shap values retry 1\n",
        "\n",
        "### Subtask:\n",
        "Generate SHAP values for the test sentences using the initialized SHAP explainer.\n"
      ],
      "id": "6d999323"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dee6b59"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate SHAP values for the test sentences using the initialized SHAP explainer.\n",
        "\n"
      ],
      "id": "6dee6b59"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "ef1ebc0f",
        "outputId": "0889afa7-837e-4ad6-95bd-f5d973e774aa"
      },
      "source": [
        "shap_values = explainer(test_sentences)"
      ],
      "id": "ef1ebc0f",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-71-2123370617.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    171\u001b[0m     ):\n\u001b[1;32m    172\u001b[0m         \u001b[0;34m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_partition.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             ]  # the zero index param tells the masked model what the baseline is\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mf11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mm00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mjoined_masked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_masked_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0m_assert_output_input_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mall_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/models/_transformers_pipeline.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, strings)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 output[i, self.label2id[obj[\"label\"]]] = (\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale_to_logits\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 )\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "194fb9c7"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial attempt to generate SHAP values with the `TokenClassificationPipeline` resulted in a `KeyError: 'label'`.\n",
        "*   A custom `output_transform` function was defined to restructure the pipeline's output to include 'label' and 'score' keys, aiming for compatibility with SHAP.\n",
        "*   The `shap.Explainer` was initialized with the pipeline and the custom `output_transform` function.\n",
        "*   Despite the custom transformation, subsequent attempts to generate SHAP values still resulted in a `KeyError: 'label'`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The `KeyError: 'label'` persists even with the defined custom output transformation, indicating a potential issue with how SHAP processes the transformed output or that the transformation is not correctly applied or interpreted by the explainer in this context.\n",
        "*   Further debugging is required to understand why SHAP is still expecting a 'label' key in a format that is not being provided or correctly interpreted, despite the custom transformation. This might involve examining the exact structure of the pipeline output and the expected input format of the SHAP explainer more closely.\n"
      ],
      "id": "194fb9c7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d29c5a43"
      },
      "source": [
        "## Define a custom output transform function\n",
        "\n",
        "### Subtask:\n",
        "Create a Python function that takes the output of the `TokenClassificationPipeline` and restructures it to include 'label' and 'score' keys in a format compatible with SHAP."
      ],
      "id": "d29c5a43"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ca1fac5"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `output_transform` function as described in the instructions to restructure the pipeline output."
      ],
      "id": "3ca1fac5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48fef48c"
      },
      "source": [
        "def output_transform(pipeline_output):\n",
        "    \"\"\"\n",
        "    Transforms the output of the TokenClassificationPipeline to be compatible with SHAP.\n",
        "\n",
        "    Args:\n",
        "        pipeline_output: The output from the TokenClassificationPipeline.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries with 'label' and 'score' keys for each entity.\n",
        "    \"\"\"\n",
        "    transformed_output = []\n",
        "    for sentence_output in pipeline_output:\n",
        "        sentence_transformed = []\n",
        "        for entity in sentence_output:\n",
        "            sentence_transformed.append({\n",
        "                'label': entity['entity_group'],\n",
        "                'score': entity['score']\n",
        "            })\n",
        "        transformed_output.append(sentence_transformed)\n",
        "    return transformed_output"
      ],
      "id": "48fef48c",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab15554c"
      },
      "source": [
        "## Initialize shap explainer with the custom transform\n",
        "\n",
        "### Subtask:\n",
        "Instantiate the `shap.Explainer` and pass the custom `output_transform` function to it."
      ],
      "id": "ab15554c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f08afa0"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize the SHAP Explainer with the NER pipeline and the custom output transform function."
      ],
      "id": "6f08afa0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "103dab44"
      },
      "source": [
        "explainer = shap.Explainer(ner_pipe, output_transform=output_transform)"
      ],
      "id": "103dab44",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}